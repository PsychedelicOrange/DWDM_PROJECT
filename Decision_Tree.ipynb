{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we import all the required modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u5clKWrCErLW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then after importing the csv file we check if any examples have empty values for any of the selected attributes , on which they are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"games.csv\",usecols=['opening_ply','turns','winner','black_rating','white_rating'])\n",
    "df.dropna(\n",
    "    axis=0,\n",
    "    how='any',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now For a classification model, we split the columns into X and Y , where X is the sample data with chosen features , and Y is the prediction classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       turns  white_rating  black_rating  opening_ply\n",
      "0         13          1500          1191            5\n",
      "1         16          1322          1261            4\n",
      "2         61          1496          1500            3\n",
      "3         61          1439          1454            3\n",
      "4         95          1523          1469            5\n",
      "...      ...           ...           ...          ...\n",
      "20053     24          1691          1220            2\n",
      "20054     82          1233          1196            2\n",
      "20055     35          1219          1286            3\n",
      "20056    109          1360          1227            4\n",
      "20057     78          1235          1339            3\n",
      "\n",
      "[20058 rows x 4 columns]\n",
      "      winner\n",
      "0      white\n",
      "1      black\n",
      "2      white\n",
      "3      white\n",
      "4      white\n",
      "...      ...\n",
      "20053  white\n",
      "20054  black\n",
      "20055  white\n",
      "20056  white\n",
      "20057  black\n",
      "\n",
      "[20058 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['winner'],axis=1)\n",
    "Y = df.drop(['turns','black_rating','white_rating','opening_ply'],axis=1)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20058, 4)\n"
     ]
    }
   ],
   "source": [
    "X = X.to_numpy()\n",
    "Y = Y.to_numpy()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating better attribute to predict ( Difference in rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  13    5  309]\n",
      " [  16    4   61]\n",
      " [  61    3   -4]\n",
      " ...\n",
      " [  35    3  -67]\n",
      " [ 109    4  133]\n",
      " [  78    3 -104]]\n"
     ]
    }
   ],
   "source": [
    "diff = np.subtract(X[:,1],X[:,2]) # white rating - black rating\n",
    "X = np.delete(X,[1,2],axis=1)\n",
    "X = np.column_stack((X,diff))\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here training and test data is split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3INLUm80E_uh",
    "outputId": "1b83e238-3369-4739-e749-1bc198870e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  17    3 -168]\n",
      " [  26    4 -398]\n",
      " [  61    7   65]\n",
      " ...\n",
      " [  51    3 -202]\n",
      " [  46    4 -227]\n",
      " [  27    4 -236]]\n",
      "[['black']\n",
      " ['black']\n",
      " ['white']\n",
      " ...\n",
      " ['white']\n",
      " ['black']\n",
      " ['black']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train , X_test, Y_train, Y_test = train_test_split(\n",
    "X,Y,test_size=0.05,random_state=0)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,Y_train)\n",
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score is measured , which is accuracy percentage of the model applied on the test data we split earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7587238285144566\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(X_test, Y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
